import json
from typing import overload
import uuid
from compliancecowcards.structs import cards
#As per the selected app, we're importing the app package 
import pandas as pd

class Task(cards.AbstractTask):

    def execute(self) -> dict:

        error = self.check_inputs()
        if error:
            log_file_url, error = self.upload_log_file([{ "Error": error }])
            if error:
                return { "Error": error }
            return { "LogFile": log_file_url }

        container_report_data_df = pd.DataFrame()
        container_report_file_url = self.task_inputs.user_inputs.get("ContainerScanningReport")
        if not container_report_file_url:
            error = "Container Scanning Report URL is not provided"
            log_url, log_error = self.upload_log_file([{ "Error": error }])
            if log_error:
                return {"Error": log_error}
            return {"LogFile": log_url}
        else:
            try:
               if container_report_file_url:
                    container_report_data_df, error = self.download_parquet_file_from_minio_as_df(file_url=container_report_file_url)
                    if error:
                        raise Exception(error)
            except ValueError as ve:
                error = f"Error downloading Container Scanning Report (ValueError): {str(ve)}"
                log_url, log_error = self.upload_log_file([{ "Error": error }])
                if log_error:
                    return {"Error": log_error}
                return {"LogFile": log_url}
            except FileNotFoundError as fnf_error:
                error = f"Error downloading Container Scanning Report (FileNotFoundError): {str(fnf_error)}"
                log_url, log_error = self.upload_log_file([{ "Error": error }])
                if log_error:
                    return {"Error": log_error}
                return {"LogFile": log_url}
            except ConnectionError as conn_error:
                error = f"Error downloading Container Scanning Report (ConnectionError): {str(conn_error)}"
                log_url, log_error = self.upload_log_file([{ "Error": error }])
                if log_error:
                    return {"Error": log_error}
                return {"LogFile": log_url}
 
        summary_data_df = pd.DataFrame()

        summary_data_df = self.generate_summary_data(container_report_data_df)
        summary_data_df = summary_data_df.apply(lambda row: self.update_vulnerability_details(row.to_dict()), axis=1)
        summary_data_df = pd.DataFrame(summary_data_df.tolist())
        file_name = "ContainerVulnerabilitySummaryReport"
        scanner_report_file_url, error = self.upload_df_as_parquet_file_to_minio(
            df=summary_data_df,
            file_name=file_name
        )
        if error:
            return { "Error": f"Error while uploading {file_name} file :: {error}" }
        response = {
            "ContainerVulnerabilitySummaryReport": scanner_report_file_url
        }

        return response
    
    def process_group(self, group):
        system = group['System'].values[0]
        source = group['Source'].values[0]
        resource_type = group['ResourceType'].values[0]
        resource_id = group['ResourceID'].values[0]
        resource_url = group['ResourceURL'].values[0]
        evaluated_time = group['EvaluatedTime'].values[0]
        group['Severity'] = group['Severity'].str.lower()

        return pd.Series({
            "System": system,
            "Source": source,
            "ResourceID": resource_id,
            "ResourceType": resource_type,
            "ResourceURL": resource_url,
            "CriticalVulnCount": self.get_vuls_count(group, "critical"),
            "HighVulnCount": self.get_vuls_count(group, "high"),
            "MediumVulnCount": self.get_vuls_count(group, "medium"),
            "LowVulnCount": self.get_vuls_count(group, "low"),
            "EPSSPercentileBand_>90": self.get_epss_percentile_band(group, '>90'),
            "EPSSPercentileBand_70-90": self.get_epss_percentile_band(group, '70-90'),
            "EPSSPercentileBand_50-70": self.get_epss_percentile_band(group, '50-70'),
            "EPSSPercentileBand_<50": self.get_epss_percentile_band(group, '<50'),
            "ValidationStatusCode": "", 
            "ValidationStatusNotes": "", 
            "ComplianceStatus": "",
            "ComplianceStatusReason": "",
            "EvaluatedTime": evaluated_time,
            "UserAction": "", 
            "ActionStatus": "",
            "ActionResponseURL": ""
        })

    def generate_summary_data(self, container_report_data_df):
        columns = set(['System', 'Source', 'ResourceID', 'ResourceName', 'ResourceType', 'ResourceLocation', 'ResourceTags', 'ResourceURL', 'CVEID', 'Severity', 'EPSSPercentile', 'EvaluatedTime', 'UserAction', 'ActionStatus', 'ActionResponseURL'])
        
        if not container_report_data_df.empty and len(columns.intersection(container_report_data_df.columns)) == len(columns):
            summary_data = container_report_data_df.groupby(['ResourceName']).apply(self.process_group).reset_index()
            
            summary_data['ResourceLocation'] = "N/A"
            summary_data['ResourceTags'] = "N/A"

            formatted_columns = [
                "System", "Source", "ResourceID", "ResourceName", "ResourceType", 
                "ResourceLocation", "ResourceTags", "ResourceURL", 
                "CriticalVulnCount", "HighVulnCount", "MediumVulnCount", "LowVulnCount", 
                "EPSSPercentileBand_>90", "EPSSPercentileBand_70-90", 
                "EPSSPercentileBand_50-70", "EPSSPercentileBand_<50", 
                "ValidationStatusCode", "ValidationStatusNotes", "ComplianceStatus", 
                "ComplianceStatusReason", "EvaluatedTime", "UserAction", "ActionStatus", 
                "ActionResponseURL"
            ]
            summary_data = summary_data[formatted_columns]

            return summary_data

        return pd.DataFrame(columns=formatted_columns)
        
    def get_vuls_count(self, df, severity):
        vuls_count = len(df[df['Severity'] == severity])
        return vuls_count

    def get_epss_percentile_band(self, df, percentile_band):
        df['EPSSPercentile'] = pd.to_numeric(df['EPSSPercentile'], errors='coerce')
        if percentile_band == '<50':
            count = len(df[df['EPSSPercentile'] < 50])
        elif percentile_band == '50-70':
            count = len(df[(df['EPSSPercentile'] >= 50) & (df['EPSSPercentile'] < 70)])
        elif percentile_band == '70-90':
            count = len(df[(df['EPSSPercentile'] >= 70) & (df['EPSSPercentile'] < 90)])
        elif percentile_band == '>90':
            count = len(df[df['EPSSPercentile'] >= 90])

        return count if count >= 0 else "N/A"
    
    def update_vulnerability_details(self, row):
        critical_vuln_count = row.get("CriticalVulnCount", 0)
        high_vuln_count = row.get("HighVulnCount", 0)
        epss_band = {
            "High": int(row.get("EPSSPercentileBand_70-90", 0)),
            "Critical": int(row.get("EPSSPercentileBand_>90", 0)),
        }

        if (critical_vuln_count > 0 or high_vuln_count > 0) and (
            epss_band["High"] > 0 or epss_band["Critical"] > 0):
            compliance_status = "NON_COMPLIANT"
            compliance_status_reason = "Critical or High severity code vulnerabilities found with EPSS Percentile in the High(70-90) or Critical(>90) range."
        else:
            compliance_status = "COMPLIANT"
            compliance_status_reason = "No Critical or High severity vulnerabilities with EPSS Percentile in the High(70-90) or Critical(>90) range."

        validation_status_code = f"{critical_vuln_count}_CRT_{high_vuln_count}_HIGH_VL_PR"
        
        if critical_vuln_count == 0 and high_vuln_count == 0:
            vuln_status = "NO_CRT_HIGH_VL_PR"
        else:
            vuln_status = f"{critical_vuln_count}_CRT_{high_vuln_count}_HIGH_VL_PR"

        if epss_band["High"] == 0 and epss_band["Critical"] == 0:
            epss_status = "NO_CRT_HIGH_EPSS_PR"
        else:
            epss_status = f"{epss_band['Critical']}_CRT_{epss_band['High']}_HIGH_EPSS_PR"

        validation_status_code = f"{vuln_status}_{epss_status}"
            
        if critical_vuln_count == 0 and high_vuln_count == 0:
            if epss_band["High"] == 0 and epss_band["Critical"] == 0:
                validation_status_notes = "No Critical or High severity vulnerabilities and no vulnerabilities with High or Critical EPSS Percentile."
            else:
                validation_status_notes = (
                    f"No Critical or High severity vulnerabilities, but {epss_band['Critical']} vulnerabilities with critical(>90) EPSS Percentile and "
                    f"{epss_band['High']} vulnerabilities with High(70-90) EPSS Percentile."
                )
        else:
            if epss_band["High"] == 0 and epss_band["Critical"] == 0:
                validation_status_notes = (
                    f"Contains {critical_vuln_count} Critical and {high_vuln_count} High severity vulnerabilities, but no vulnerabilities with High or Critical EPSS Percentile."
                )
            else:
                validation_status_notes = (
                    f"Contains {critical_vuln_count} Critical and {high_vuln_count} High severity vulnerabilities, and "
                    f"{epss_band['Critical']} vulnerabilities with critical(>90) EPSS Percentile and {epss_band['High']} vulnerabilities with High(70-90) EPSS Percentile."
                )

        row.update({
            "ValidationStatusCode": validation_status_code,
            "ValidationStatusNotes": validation_status_notes,
            "ComplianceStatus": compliance_status,
            "ComplianceStatusReason": compliance_status_reason
        })
        return row
    
    def upload_log_file(self, error_data):
        if not isinstance(error_data, list):
            error_data = [error_data]
        log_file_content = json.dumps(error_data, indent=4)
        file_name = f"LogFile-{str(uuid.uuid4())}.json"
        content_type = "application/json"
        file_url, error = self.upload_file_to_minio(
            file_content=log_file_content.encode('utf-8'),
            file_name=file_name,
            content_type=content_type
        )
        if error:
            return None, f"Error while uploading LogFile: {error}"
        return file_url, None

    def check_inputs(self):
        if not self.task_inputs:
            return 'Task inputs are missing'
        user_object = self.task_inputs.user_object
        if (
            user_object is None
            or user_object.app is None
            or user_object.app.application_url is None
            or user_object.app.user_defined_credentials is None
        ):
            return 'User defined credentials are missing"'

        return ""